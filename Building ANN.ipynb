{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Network or Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artificial neural network is the term used in Artificial World and Neural network is the term used in Biological world, nothing difference in their functionality. Artificial Neural Network is new compared to neural network which is around 5000 years old...Artificial neural network works as neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session we buils a basic Artiicial Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component of Artificial Neural Network\n",
    "1. Layers\n",
    "2. Nodes\n",
    "3. Weights\n",
    "4. Bias\n",
    "5. Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://cocl.us/neural_network_example\" alt=\"Neural Network Example\" width=600px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How ANN works.\n",
    "\n",
    "We pass the input and weight, perforn some linear function on that like input*weight, add bias to that linear function ((input*weight) + bias) and pass under the activation function (like RelU, Sigmoid, Tanh)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Weights and Bias\n",
    "\n",
    "Let's start by randomly initializing the weights and the biases in the network. We have 6 weights and 3 biases, one for each node in the hidden layer as well as for each node in the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # import Numpy library to generate \n",
    "\n",
    "weights = np.around(np.random.uniform(size=6), decimals=2) # initialize the weights\n",
    "biases = np.around(np.random.uniform(size=3), decimals=2) # initialize the biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92 0.9  0.03 0.96 0.14 0.28]\n",
      "[0.61 0.94 0.85]\n"
     ]
    }
   ],
   "source": [
    "print(weights)\n",
    "print(biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x1 is: 1.8 and Input x2 is: -0.85\n"
     ]
    }
   ],
   "source": [
    "# Inputs\n",
    "\n",
    "x_1 = 1.8 # input 1\n",
    "x_2 = -0.85 # input 2\n",
    "\n",
    "print('Input x1 is: {} and Input x2 is: {}'.format(x_1, x_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above figure, now we have x1 and x2, we have w1, w2, w3, w4, we have b 1,1 and b 1,2, and we use Sigmoid activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted sum of the inputs at the first node in the hidden layer is 1.5010000000000001\n"
     ]
    }
   ],
   "source": [
    "# Compute Z 1,1\n",
    "\n",
    "z_11 = (x_1 * weights[0]) + (x_2 * weights[1]) + biases[0]\n",
    "print('Weighted sum of the inputs at the first node in the hidden layer is {}'.format(z_11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted sum of the inputs at the Second node in the hidden layer is 0.17800000000000005\n"
     ]
    }
   ],
   "source": [
    "# Compute Z 1,2\n",
    "\n",
    "z_12 = (x_1 * weights[2]) + (x_2 * weights[3]) + biases[1]\n",
    "print('Weighted sum of the inputs at the Second node in the hidden layer is {}'.format(z_12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation of the first node in the hidden layer is 0.82\n"
     ]
    }
   ],
   "source": [
    "# compute the activation of the first node i.e a_11, in hidden layer\n",
    "\n",
    "a_11 = 1.0 / (1.0 + np.exp(-z_11))\n",
    "\n",
    "print('Activation of the first node in the hidden layer is {}'.format(np.around(a_11, decimals=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation of the second node in the hidden layer is 0.54\n"
     ]
    }
   ],
   "source": [
    "# compute the activation of the first node i.e a_12, in hidden layer\n",
    "\n",
    "a_12 = 1.0 / (1.0 + np.exp(-z_12))\n",
    "\n",
    "print('Activation of the second node in the hidden layer is {}'.format(np.around(a_12, decimals=2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- These activations will be the inputs to the next layer i.e output layer. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These activations i.e a_11 and a_12 will serve as the inputs to the next layer i.e output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted sum of the inputs at the node in the output layer is 1.12\n"
     ]
    }
   ],
   "source": [
    "z_2 = a_11 * weights[4] + a_12 * weights[5] +biases[2]\n",
    "\n",
    "print('Weighted sum of the inputs at the node in the output layer is {}'.format(np.around(z_2, decimals=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output of the network for x1 = 1.8 and x2 = -0.85 is 0.75\n"
     ]
    }
   ],
   "source": [
    "# Compute activation at output of the network.\n",
    "\n",
    "a_2 = 1.0 / (1.0 + np.exp(-z_2))\n",
    "print('The output of the network for x1 = 1.8 and x2 = -0.85 is {}'.format(np.around(a_2, decimals=2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is simple ANN and it's working with inefficient approach..........In real worls scenario/use case the no of feature, the number of hidden layer, the number of nodes in each hidden layer, which activation function is to used in hidden layer, which activation function is to used in output layer.\n",
    "\n",
    "#### I make this simple beacuse of learning purpose, all these are challenging and time taking in real time use case\n",
    "\n",
    "#### For adding layers, nodes, activation function or any other...python has no of library like keras, sklearn, etc...i do it here in inefficient approach for learning purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalize Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consist of n input\n",
    "#### Many hidden layers\n",
    "#### Each hidden layers have m nodes\n",
    "#### Output layer\n",
    "\n",
    "#### The network is showing one hidden layer, but we will code the network to have many hidden layers, output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://cocl.us/general_neural_network\" alt=\"Neural Network General\" width=600px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize a Network\n",
    "Defining the formal structure of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2 # number of inputs\n",
    "num_hidden_layers = 2 # number of hidden layers\n",
    "m = [2, 2] # number of nodes in each hidden layer\n",
    "num_nodes_output = 1 # number of nodes in the output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go ahead and inititailize the weights and the biases in the network to random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layer_1': {'node_1': {'weights': array([0.  , 0.52]), 'bias': array([0.55])}, 'node_2': {'weights': array([0.49, 0.77]), 'bias': array([0.16])}}, 'layer_2': {'node_1': {'weights': array([0.76, 0.02]), 'bias': array([0.14])}, 'node_2': {'weights': array([0.12, 0.31]), 'bias': array([0.67])}}, 'output': {'node_1': {'weights': array([0.47, 0.82]), 'bias': array([0.29])}}}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # import the Numpy library\n",
    "\n",
    "num_nodes_previous = n # number of nodes in the previous layer\n",
    "\n",
    "network = {} # initialize network an an empty dictionary\n",
    "\n",
    "# loop through each layer and randomly initialize the weights and biases associated with each node\n",
    "# notice how we are adding 1 to the number of hidden layers in order to include the output layer\n",
    "for layer in range(num_hidden_layers + 1): \n",
    "    \n",
    "    # determine name of layer\n",
    "    if layer == num_hidden_layers:\n",
    "        layer_name = 'output'\n",
    "        num_nodes = num_nodes_output\n",
    "    else:\n",
    "        layer_name = 'layer_{}'.format(layer + 1)\n",
    "        num_nodes = m[layer]\n",
    "#         print(\"layer\",layer)\n",
    "#         print(\"M\", m)\n",
    "#         print(num_nodes)\n",
    "#         print(\"m_layer\", m[layer])\n",
    "    \n",
    "    # initialize weights and biases associated with each node in the current layer\n",
    "    network[layer_name] = {}\n",
    "    for node in range(num_nodes):\n",
    "        node_name = 'node_{}'.format(node+1)\n",
    "        network[layer_name][node_name] = {\n",
    "            'weights': np.around(np.random.uniform(size=num_nodes_previous), decimals=2),\n",
    "            'bias': np.around(np.random.uniform(size=1), decimals=2),\n",
    "        }\n",
    "    \n",
    "    num_nodes_previous = num_nodes\n",
    "    \n",
    "print(network) # print network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put above code in function so that we are construct neural network when we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def building_network(num_inputs, num_hidden_layers, num_nodes_hidden, num_nodes_output):\n",
    "    \n",
    "    num_nodes_previous = num_inputs # number of nodes in the previous layer\n",
    "\n",
    "    network = {}\n",
    "    \n",
    "    # loop through each layer and randomly initialize the weights and biases associated with each layer\n",
    "    for layer in range(num_hidden_layers + 1):\n",
    "        \n",
    "        if layer == num_hidden_layers:\n",
    "            layer_name = 'output' # name last layer in the network output\n",
    "            num_nodes = num_nodes_output\n",
    "        else:\n",
    "            layer_name = 'layer_{}'.format(layer + 1) # otherwise give the layer a number\n",
    "            num_nodes = num_nodes_hidden[layer] \n",
    "        \n",
    "        # initialize weights and bias for each node\n",
    "        network[layer_name] = {}\n",
    "        for node in range(num_nodes):\n",
    "            node_name = 'node_{}'.format(node+1)\n",
    "            network[layer_name][node_name] = {\n",
    "                'weights': np.around(np.random.uniform(size=num_nodes_previous), decimals=2),\n",
    "                'bias': np.around(np.random.uniform(size=1), decimals=2),\n",
    "            }\n",
    "    \n",
    "        num_nodes_previous = num_nodes\n",
    "\n",
    "    return network # return the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "network1 = building_network(5, 3, [3, 2, 3], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ComputeWeighted sum\n",
    "\n",
    "def weight_sum(inputs, weights, bias):\n",
    "    return np.sum(inputs * weights) + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating 5 inputs to feed in **network1**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The inputs to the network are [0.15 0.74 0.26 0.53 0.01]\n"
     ]
    }
   ],
   "source": [
    "from random import seed\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(12)\n",
    "inputs = np.around(np.random.uniform(size=5), decimals=2)\n",
    "\n",
    "print('The inputs to the network are {}'.format(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the weighted_sum function to compute the weighted sum at the first node in the first hidden layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted sum at the first node in the hidden layer is 1.52\n"
     ]
    }
   ],
   "source": [
    "node_weights = network1['layer_1']['node_1']['weights']\n",
    "node_bias = network1['layer_1']['node_1']['bias']\n",
    "\n",
    "weighted_sum = weight_sum(inputs, node_weights, node_bias)\n",
    "print('Weighted sum at the first node in the hidden layer is {}'.format(np.around(weighted_sum[0], decimals=2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Node Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output of each node is simply a non-linear tranformation of the weighted sum. We use activation functions for this mapping, use sigmoid activation function for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activate_node(weighted_sum):\n",
    "    return 1.0 / (1.0 + np.exp(-1 * weighted_sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute o/p of first node of first hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of the first node in the hidden layer is 0.82\n"
     ]
    }
   ],
   "source": [
    "n1_output  = activate_node(weight_sum(inputs, node_weights, node_bias))\n",
    "print('Output of the first node in the hidden layer is {}'.format(np.around(n1_output[0], decimals=2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward Propagation, A Final Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can perform predictions is to put everything together.....create a function that applies the weight_sum and activate_node functions to each node in network and propagates data all the way to output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_propagation(network, inputs):\n",
    "    \n",
    "    layer_inputs = list(inputs) # start with the input layer as the input to the first hidden layer\n",
    "    \n",
    "    for layer in network:\n",
    "        \n",
    "        layer_data = network[layer]\n",
    "        \n",
    "        layer_outputs = [] \n",
    "        for layer_node in layer_data:\n",
    "        \n",
    "            node_data = layer_data[layer_node]\n",
    "        \n",
    "            # compute the weighted sum and the output of each node at the same time \n",
    "            node_output = activate_node(weight_sum(layer_inputs, node_data['weights'], node_data['bias']))\n",
    "            layer_outputs.append(np.around(n1_output[0], decimals=2))\n",
    "            \n",
    "        if layer != 'output':\n",
    "            print('The outputs of the nodes in hidden layer number {} is {}'.format(layer.split('_')[1], layer_outputs))\n",
    "    \n",
    "        layer_inputs = layer_outputs # set the output of this layer to be the input to next layer\n",
    "\n",
    "    network_predictions = layer_outputs\n",
    "    return network_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The outputs of the nodes in hidden layer number 1 is [0.82, 0.82, 0.82]\n",
      "The outputs of the nodes in hidden layer number 2 is [0.82, 0.82]\n",
      "The outputs of the nodes in hidden layer number 3 is [0.82, 0.82, 0.82]\n",
      "Predicted value by the network for given input is 0.82\n"
     ]
    }
   ],
   "source": [
    "pred1 = f_propagation(network1, inputs)\n",
    "print('Predicted value by the network for given input is {}'.format(np.around(pred1[0], decimals=2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above is the code to define a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First use building_network function to create neural network and define its weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_net = building_network(5, 3, [2, 3, 2], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Given Input\n",
    "\n",
    "inputs = np.around(np.random.uniform(size=5), decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.47, 0.04, 0.08, 0.73, 0.64])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute network predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The outputs of the nodes in hidden layer number 1 is [0.82, 0.82]\n",
      "The outputs of the nodes in hidden layer number 2 is [0.82, 0.82, 0.82]\n",
      "The outputs of the nodes in hidden layer number 3 is [0.82, 0.82]\n",
      "The predicted values by the network for the given input are [0.82, 0.82, 0.82]\n"
     ]
    }
   ],
   "source": [
    "predi1 = f_propagation(my_net, inputs)\n",
    "print('The predicted values by the network for the given input are {}'.format(predi1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tenserflow1",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
